import { config } from 'dotenv';
import { put, list } from '@vercel/blob';
import { readdir, readFile } from 'fs/promises';
import { join } from 'path';
import { writeFile } from 'fs/promises';

// Load environment variables from .env.local
config({ path: '.env.local' });

const DATA_DIR = './public/data';
const BLOB_TOKEN = process.env.BLOB_READ_WRITE_TOKEN;
const CONCURRENCY = 3; // Upload 3 files at once

if (!BLOB_TOKEN) {
  console.error('‚ùå Error: BLOB_READ_WRITE_TOKEN environment variable not set');
  console.error('Get your token from: https://vercel.com/dashboard/stores');
  process.exit(1);
}

async function getExistingBlobs() {
  try {
    const { blobs } = await list({ token: BLOB_TOKEN });
    return new Set(blobs.map(b => b.pathname));
  } catch (error) {
    console.log('‚ö†Ô∏è  Could not list existing blobs:', error.message);
    return new Set();
  }
}

async function uploadFile(filename, filepath, existingBlobs) {
  // Skip if already uploaded
  if (existingBlobs.has(filename)) {
    console.log(`‚è≠Ô∏è  Skipping ${filename} (already uploaded)`);
    const existingUrl = `https://${BLOB_TOKEN.split('_')[2]}.public.blob.vercel-storage.com/${filename}`;
    return { filename, url: existingUrl, skipped: true };
  }

  console.log(`‚¨ÜÔ∏è  Uploading ${filename}...`);

  try {
    const fileContent = await readFile(filepath);
    const blob = await put(filename, fileContent, {
      access: 'public',
      token: BLOB_TOKEN,
    });

    console.log(`‚úÖ Uploaded: ${blob.url}`);
    return { filename, url: blob.url, skipped: false };
  } catch (error) {
    console.error(`‚ùå Failed to upload ${filename}:`, error.message);
    return { filename, url: null, error: error.message };
  }
}

async function uploadInBatches(files, batchSize) {
  const results = [];

  for (let i = 0; i < files.length; i += batchSize) {
    const batch = files.slice(i, i + batchSize);
    console.log(`\nüì¶ Batch ${Math.floor(i / batchSize) + 1}/${Math.ceil(files.length / batchSize)}: Uploading ${batch.length} files in parallel...\n`);

    const batchResults = await Promise.all(batch.map(({ filename, filepath, existingBlobs }) =>
      uploadFile(filename, filepath, existingBlobs)
    ));

    results.push(...batchResults);
  }

  return results;
}

async function uploadFiles() {
  console.log('üìÅ Reading files from', DATA_DIR);

  const files = await readdir(DATA_DIR);
  const lidarFiles = files.filter(f => f.endsWith('.laz') || f.endsWith('.ply'));

  console.log(`\nüì¶ Found ${lidarFiles.length} LIDAR files to upload\n`);

  // Check what's already uploaded
  console.log('üîç Checking for existing uploads...');
  const existingBlobs = await getExistingBlobs();

  if (existingBlobs.size > 0) {
    console.log(`‚úì Found ${existingBlobs.size} already uploaded files\n`);
  }

  // Prepare file list with paths
  const filesToProcess = lidarFiles.map(filename => ({
    filename,
    filepath: join(DATA_DIR, filename),
    existingBlobs
  }));

  // Upload in parallel batches
  const results = await uploadInBatches(filesToProcess, CONCURRENCY);

  // Build URL map from results
  const urlMap = {};
  let uploadedCount = 0;
  let skippedCount = 0;
  let errorCount = 0;

  for (const result of results) {
    if (result.url) {
      urlMap[result.filename] = result.url;
      if (result.skipped) {
        skippedCount++;
      } else {
        uploadedCount++;
      }
    } else {
      errorCount++;
    }
  }

  console.log('\nüìã Summary:');
  console.log(`‚úÖ Uploaded: ${uploadedCount}`);
  console.log(`‚è≠Ô∏è  Skipped: ${skippedCount}`);
  if (errorCount > 0) console.log(`‚ùå Errors: ${errorCount}`);
  console.log(`\nüì¶ Total files in blob: ${Object.keys(urlMap).length}`);

  // Save URL map to JSON file
  await writeFile('./blob-urls.json', JSON.stringify(urlMap, null, 2));
  console.log('\nüíæ Saved URL mapping to blob-urls.json');

  // Generate JS config file for the app
  const configContent = `// Auto-generated by upload-to-blob-parallel.js
// Do not edit manually - run 'npm run upload-blob' to regenerate

export const BLOB_URLS = ${JSON.stringify(urlMap, null, 2)};

// Helper function to get blob URL or fallback to local path (for dev)
export function getDataUrl(filename) {
  // In production, use Blob URL
  if (BLOB_URLS[filename]) {
    return BLOB_URLS[filename];
  }

  // In development, use local path
  return \`/data/\${filename}\`;
}
`;

  await writeFile('./src/config/blobUrls.js', configContent);
  console.log('üíæ Generated src/config/blobUrls.js');
  console.log('\n‚úÖ All done! Your LIDAR files are now hosted on Vercel Blob.');
}

uploadFiles().catch(console.error);
